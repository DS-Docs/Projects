<script type="text/javascript">
        var gk_isXlsx = false;
        var gk_xlsxFileLookup = {};
        var gk_fileData = {};
        function filledCell(cell) {
          return cell !== '' && cell != null;
        }
        function loadFileData(filename) {
        if (gk_isXlsx && gk_xlsxFileLookup[filename]) {
            try {
                var workbook = XLSX.read(gk_fileData[filename], { type: 'base64' });
                var firstSheetName = workbook.SheetNames[0];
                var worksheet = workbook.Sheets[firstSheetName];

                // Convert sheet to JSON to filter blank rows
                var jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, blankrows: false, defval: '' });
                // Filter out blank rows (rows where all cells are empty, null, or undefined)
                var filteredData = jsonData.filter(row => row.some(filledCell));

                // Heuristic to find the header row by ignoring rows with fewer filled cells than the next row
                var headerRowIndex = filteredData.findIndex((row, index) =>
                  row.filter(filledCell).length >= filteredData[index + 1]?.filter(filledCell).length
                );
                // Fallback
                if (headerRowIndex === -1 || headerRowIndex > 25) {
                  headerRowIndex = 0;
                }

                // Convert filtered JSON back to CSV
                var csv = XLSX.utils.aoa_to_sheet(filteredData.slice(headerRowIndex)); // Create a new sheet from filtered array of arrays
                csv = XLSX.utils.sheet_to_csv(csv, { header: 1 });
                return csv;
            } catch (e) {
                console.error(e);
                return "";
            }
        }
        return gk_fileData[filename] || "";
        }
        </script><!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Science & Generative AI by SATISH @ Sathya Technologies</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            line-height: 1.6;
            background-color: #f4f4f4;
        }
        h1, h2, h3 {
            color: #333;
        }
        .timer {
            font-size: 24px;
            font-weight: bold;
            color: #d32f2f;
            margin-bottom: 20px;
        }
        pre {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        code {
            font-family: Consolas, monospace;
        }
        .section {
            background: #fff;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>Data Science & Generative AI by SATISH @ Sathya Technologies</h1>
    <h2>Deep Learning Project: MNIST Handwritten Digit Classification</h2>
    <div class="section">
        <h3>45-Minute Timer</h3>
        <div id="timer" class="timer">45:00</div>
        <button onclick="startTimer()">Start Timer</button>
        <script>
            function startTimer() {
                let timeLeft = 45 * 60;
                const timerElement = document.getElementById('timer');
                const interval = setInterval(() => {
                    const minutes = Math.floor(timeLeft / 60);
                    const seconds = timeLeft % 60;
                    timerElement.textContent = `${minutes}:${seconds < 10 ? '0' : ''}${seconds}`;
                    timeLeft--;
                    if (timeLeft < 0) {
                        clearInterval(interval);
                        timerElement.textContent = "Time's Up!";
                        alert("45 minutes are up!");
                    }
                }, 1000);
            }
        </script>
    </div>
    <div class="section">
        <h3>Project Overview</h3>
        <p>
            This project involves building a deep learning model to classify handwritten digits (0-9) using the MNIST dataset. The model uses a Convolutional Neural Network (CNN) implemented in Python with TensorFlow/Keras. The goal is to train the model to accurately predict the digit in an image.
        </p>
    </div>
    <div class="section">
        <h3>Dataset Description</h3>
        <p>
            The <a href="http://yann.lecun.com/exdb/mnist/" target="_blank">MNIST dataset</a> contains 70,000 grayscale images of handwritten digits (0-9), each of size 28x28 pixels. It is split into:
        </p>
        <ul>
            <li><strong>Training set</strong>: 60,000 images</li>
            <li><strong>Test set</strong>: 10,000 images</li>
        </ul>
        <p>
            Each image is labeled with the corresponding digit. The dataset is included in TensorFlow/Keras and can be loaded directly.
        </p>
    </div>
    <div class="section">
        <h3>Python Code</h3>
        <p>
            Below is the complete Python code to load the dataset, preprocess it, build a CNN model, train it, and evaluate its performance.
        </p>
        <pre><code>import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
import matplotlib.pyplot as plt

# Load and preprocess the MNIST dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Normalize pixel values to range [0, 1]
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Reshape images to include channel dimension (28, 28, 1)
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# Convert labels to categorical (one-hot encoding)
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)

# Build the CNN model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"Test accuracy: {test_accuracy:.4f}")

# Visualize training results
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
</code></pre>
    </div>
    <div class="section">
        <h3>Explanation</h3>
        <p><strong>Step-by-Step Breakdown:</strong></p>
        <ol>
            <li><strong>Loading the Dataset</strong>: The MNIST dataset is loaded using <code>tf.keras.datasets.mnist.load_data()</code>. It provides training and test sets with images and labels.</li>
            <li><strong>Preprocessing</strong>: Images are normalized by dividing pixel values by 255 to scale them to [0, 1]. The images are reshaped to include a channel dimension (28x28x1) for CNN compatibility. Labels are converted to one-hot encoded format for multi-class classification.</li>
            <li><strong>Building the Model</strong>: A CNN is created with two convolutional layers (32 and 64 filters), each followed by max-pooling to reduce spatial dimensions. The flattened output is passed through dense layers (128 neurons and 10 output neurons for 10 classes).</li>
            <li><strong>Compiling the Model</strong>: The model uses the Adam optimizer, categorical crossentropy loss (suitable for multi-class classification), and tracks accuracy.</li>
            <li><strong>Training</strong>: The model is trained for 5 epochs with a batch size of 64, using 20% of the training data for validation.</li>
            <li><strong>Evaluation</strong>: The model is evaluated on the test set, and accuracy is printed.</li>
            <li><strong>Visualization</strong>: Training and validation accuracy are plotted to visualize model performance over epochs.</li>
        </ol>
        <p><strong>Expected Output</strong>: The model typically achieves a test accuracy of ~98-99% after 5 epochs, indicating strong performance in classifying handwritten digits.</p>
    </div>
    <div class="section">
        <h3>Answers to Common Questions</h3>
        <p><strong>Q1: Why use a CNN instead of a regular neural network?</strong></p>
        <p>A: CNNs are designed for image data, as they capture spatial patterns (e.g., edges, shapes) through convolutional filters, making them more efficient than fully connected networks for this task.</p>
        <p><strong>Q2: Why normalize the pixel values?</strong></p>
        <p>A: Normalizing to [0, 1] ensures faster convergence during training by standardizing input data, as neural networks perform better with scaled inputs.</p>
        <p><strong>Q3: What is the purpose of one-hot encoding?</strong></p>
        <p>A: One-hot encoding converts labels (0-9) into a binary matrix, allowing the model to output probabilities for each class and compute loss correctly.</p>
    </div>
    <div class="section">
        <h3>Additional Notes</h3>
        <p>
            To run this code, ensure you have TensorFlow installed (<code>pip install tensorflow</code>). The MNIST dataset is automatically downloaded when you run the code. This project is ideal for beginners to understand deep learning concepts like CNNs, data preprocessing, and model evaluation.
        </p>
        <p>
            For further learning, explore advanced datasets like CIFAR-10 or try experimenting with hyperparameters (e.g., more epochs, different layer sizes) to improve accuracy.
        </p>
    </div>
</body>
</html>